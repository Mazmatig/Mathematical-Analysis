\documentclass[12pt]{article}
\pagestyle{plain}
\usepackage{latexsym,amsmath,amssymb}
\usepackage{amsthm}
%\usepackage[notref,notcite]{showkeys}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{thmtools}
\usepackage{wrapfig}
\usepackage{extarrows}
\usepackage{breqn}

\usepackage{enumitem}
\graphicspath{ {images/} }


\setlength{\oddsidemargin}{1pt}
\setlength{\evensidemargin}{1pt}
\setlength{\marginparwidth}{30pt} % these gain 53pt width
\setlength{\topmargin}{1pt}       % gains 26pt height
\setlength{\headheight}{1pt}      % gains 11pt height
\setlength{\headsep}{1pt}         % gains 24pt height
%\setlength{\footheight}{12 pt} 	  % cannot be changed as number must fit
\setlength{\footskip}{24pt}       % gains 6pt height
\setlength{\textheight}{650pt}    % 528 + 26 + 11 + 24 + 6 + 55 for luck
\setlength{\textwidth}{460pt}     % 360 + 53 + 47 for luck

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\setcounter{problem}{0}
%\numberwithin{problem}{chapter}
\renewcommand\theproblem{\arabic{problem}}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{exercise}{Exercise}
\newtheorem{remark}{Remark}
\theoremstyle{definition}
\newtheorem{example}{Example}
\numberwithin{equation}{subsection}

\def\dsp{\def\baselinestretch{1.35}\large
\normalsize}
%%%%This makes a double spacing. Use this with 11pt style. If you
%%%%want to use this just insert \dsp after the \begin{document}
%%%%The correct baselinestretch for double spacing is 1.37. However
%%%%you can use different parameter.


\def\U{{\mathcal U}}









\begin{document}





\centerline{\bf Homework 1 for Math 1540}
\centerline{Zhen Yao}

\bigskip




\noindent
{\bf Problem 1.}
Prove that the trigonometric polynomials
$$
T(x)=\sum_{k=0}^n a_k\cos kx +\sum_{k=0}^n b_k\sin kx,
\quad
a_k,b_k\in\mathbb{R}
$$
form an algebra. {\em Hint:} $\cos x+ i\sin x= e^{ix}$.
\begin{proof}
With $\cos x+ i\sin x= e^{ix}$, then we can have $\cos kx = \frac{1}{2} \left(e^{ikx} + e^{-ikx}\right)$ and $\sin kx = \frac{1}{2} \left(ie^{-ikx} - ie^{ikx}\right)$. 

Now it suffices to show that $\cos(kx)\sin(lx), \cos(kx)\cos(lx), \sin(kx)\sin(lx)$ are trigonometric polynomials. We have
\begin{align*}
    \cos(kx)\sin(lx) & = \frac{1}{4} \left(e^{ikx} + e^{-ikx}\right) \left(ie^{-ilx} - ie^{ilx}\right) \\
    & = \frac{1}{4} \left(ie^{i(k-l)x} - ie^{i(k+l)x} + ie^{-i(k+l)x} - ie^{i(l-k)x} \right) \\
    & = - \frac{1}{2} \sin((k-l)x) + \frac{1}{2} \sin((k+l)x)
\end{align*}
which is also a trigonometric polynomial. Similarly, $\cos(kx)\cos(lx), \sin(kx)\sin(lx)$ are also trigonometric polynomial. Thus, trigonometric polynomials form an algebra.
\end{proof}

\medskip

\noindent
{\bf Problem 2.}
Let $S^1=\{ z\in\mathbb{C}:\, |z|=1\}$ be the unit circle in the complex plane.
Let $\mathcal{A}$ be the algebra of functions of the form
$$
f\left(e^{i\theta}\right)=\sum_{n=0}^N c_n e^{in\theta},
\quad
c_n\in\mathbb{C},\, \theta\in\mathbb{R}.
$$
It is easy to see that
$f\equiv 1$ belongs of $\mathcal{A}$ and $\mathcal{A}$ separates points
(do not prove it).
Prove that there are complex valued functions on $S^1$ that cannot be uniformly approximated by functions in $\mathcal{A}$.
{\em Hint:} For $f\in \mathcal{A}$
$$
\int_0^{2\pi} f\left(e^{i\theta}\right)e^{i\theta}\, d\theta =0\, .
$$
\begin{proof}
The function $f(z) = z\in \mathcal{A}$ separates points in $S^1$. And we can know that $\frac{1}{z} = e^{-i\theta}$ is not in the closure of $\mathcal{A}$, since
\begin{align*}
    \int^{2\pi}_0 e^{-i\theta} e^{i\theta} d\theta = 2\pi.
\end{align*}
\end{proof}

\noindent{\bf Method II for Problem 2.}
\begin{proof}
Let $f:S^1 \to \mathbb{C}$ and $f\left(e^{i\theta} \right) = \cos \theta = {\rm Re}\, \left(e^{i\theta} \right)$, then we have
\begin{align*}
    \int^{2\pi}_0 f\left(e^{i\theta} \right)e^{i\theta} d\, \theta = \int^{2\pi}_0 \cos \theta (\cos \theta + i \sin \theta) d\, \theta \neq 0.
\end{align*}
If $g\in \mathcal{A}$, then we have 
\begin{align*}
    \int_0^{2\pi} g\left(e^{i\theta}\right)e^{i\theta}\, d\theta & = \sum^N_0 c_n \int^{2\pi}_0 e^{in\theta} e^{i\theta} \, d\theta \\
    & = \sum^N_0 c_n \left(\int^{2\pi}_0 \cos(n+1)\theta \, d\theta + i \int^{2\pi}_0 \sin(n+1)\theta \, d\theta \right) \\
    & = 0.
\end{align*}

Now we suppose $\mathcal{A}\ni g_k \rightrightarrows f$, then we have $g_k\left(e^{i\theta}\right) e^{i\theta} \rightrightarrows f\left(e^{i\theta}\right) e^{i\theta}$ and 
\begin{align*}
    0 = \int^{2\pi}_0 g_k\left(e^{i\theta}\right) e^{i\theta} \, d\theta \to \int^{2\pi}_0 f\left(e^{i\theta}\right) e^{i\theta} \, d\theta \neq 0
\end{align*}
which is a contradiction. 
\end{proof}

\medskip


\noindent
{\bf Problem 3.}
Prove that complex polynomials
$$
p(z) = \sum_{n=0}^N c_n z^n,
\quad
c_n\in\mathbb{C}
$$
are not dense in $C(\overline{D},\mathbb{C})$, where
$$
\overline{D} = \{ z\in\mathbb{C}:\, |z|\leq 1\}
$$
is the unit disc in $\mathbb{C}$.
{\em Hint:} Consider $f(z)=\overline{z}$. Is the previous exercise
helpful?
\begin{proof}
For $z = e^{i\theta} = \cos x + i\sin x$, we have $\bar{z} = z^{-1}$. Then, 
\begin{align*}
    \bar{p}(z) = \sum^N_{n=0} \bar{c_n} z^{-n}
\end{align*}
which is not a polynomial, since the exponents are negative.
\end{proof}

\noindent{\bf Method II for Problem 3.}
\begin{proof}
Suppose $g_m \rightrightarrows f$, then $g_k\left(e^{i\theta}\right) \rightrightarrows f\left(e^{i\theta}\right)$, where $g_k$ restricted to $S^1 = \{ z\in\mathbb{C}:\, |z|=1\}$ converges uniformly to $f$ which is also restricted to $S^1$. Now we take $f\left(e^{i\theta}\right) = {\rm Re}\,\left(e^{i\theta}\right) = \cos \theta$ and $g_k\left(e^{i\theta}\right) = \sum^N_{n=0}c_n e^{in\theta}$, then we can use the similar argument as Method II for problem 2.
\end{proof}

\medskip

\noindent
{\bf Problem 4.}
We know that if $f:[a,b]\to\mathbb{R}$ is continuous and
\begin{equation}
\label{1}
\int_a^b f(x)x^n\, dx = 0
\end{equation}
for $n=0,1,2,3,\ldots$, then $f(x)=0$ for all $a\leq x\leq b$.
We proved it using the Weierstrass theorem.
Suppose now that $f:[a,b]\to\mathbb{R}$ is continuous and (\ref{1})
holds for all $n\geq 2011$. Does it follow that
$f(x)=0$ for all $a\leq x\leq b$?
\begin{proof}
Set $g(x) = x^{2011}f(x)$, and then $\int^b_a g(x)x^k dx = 0$ for $k = 0,1,2,\cdot$, which implies $g(x) = 0$. Then, we know that $f(x) = 0$ for all $x\neq 0$.

If $a > 0$, then $f(x) = 0$ on $[a,b]$. If $a\neq 0$, then with continuity of $f$, we have $f(0) = 0$. Thus, $f(x) = 0$ for all $a\leq x\leq b$.
\end{proof}

\medskip


\noindent
{\bf Problem 5.}
Prove that if $f:[0,1]\to\mathbb{R}$ is such that
$$
\int_0^1 f(x) e^{nx}\, dx = 0
\quad
\mbox{for all $n=0,1,2,\ldots$,}
$$
then $f(x)=0$ for all $0\leq x\leq 1$.
Provide two proofs following the methods:
\begin{enumerate}
    \item[(a)] Use the Stone-Weierstrass theorem.
    \item[(b)] Use the change of variables formula and apply
the Weierstrass theorem.
\end{enumerate}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item There exists a sequence of the form $p_n(x) = \sum^\infty_{n=0}c_n e^{nx}$ such that converges uniformly to $f(x)$. Since $f$ is continuous on $[0,1]$, hence bounded. Then $\{p_n(x)\}$ is also bounded, and hence $p_n f$ converges uniformly to $f^2$. Then we have
    \begin{align*}
        \int^1_0 f^2(x)\,dx = \lim_{n\to\infty} \int^1_0 p_n(x) f(x)\, dx = 0,
    \end{align*}
    which implies $f(x) = 0, x\in[0,1]$.
    \item Let $e^x = y$, then we have $y = \ln x$, and
    \begin{align*}
        \int_0^1 f(x) e^{nx}\, dx = \int_1^e f(\ln y) y^{n-1}\, dy = 0.
    \end{align*}
    With previous problem, we have $f(\ln y) = 0, y\in[1,e]$, which is equivalent to that $f(x) = 0, x\in[0,1]$.
\end{enumerate}
\end{proof}

\medskip

\noindent
{\bf Problem 6.}
Prove that if $X$ is a compact metric space and $f:X\to X$
is a continuous mapping such that
$$
d(f(x),f(y))<d(x,y)
\quad
\mbox{for all $x,y\in X$},
$$
then there is a fixed point of $f$, i.e. $x\in X$ such that $f(x)=x$.
\begin{proof}
Define $\alpha = \inf_{x\in X} d(x, f(x))$, and $x \mapsto d(x,f(x))$ is continuous, then $\alpha$ is attained. Let $\alpha = d(x_0,f(x_0))$, and we need to prove that $f(x_0) = x_0$.

Suppose if not, i.e., $f(x_0) \neq x_0$, then we have
\begin{align*}
    \alpha \leq d(f(f(x_0)), f(x_0)) < d(f(x_0), x_0) = \alpha
\end{align*}
where we used the fact that $d(f(x),f(y))<d(x,y)$, for all$x,y\in X$. Then this is a contradiction.
\end{proof}

\medskip


\noindent
{\bf Problem 7.}
Find an example of a function $f:\mathbb{R}\to\mathbb{R}$ such that
$$
|f(x)-f(y)|<|x-y|
\quad
\mbox{for all $x,y\in\mathbb{R}$}
$$
and $f$ has no fixed point. You can find an explicit formula for $f$, but
you do not have to. It is enough if you find a convincing argument
that such a function exists. You do not have to be very precise, but your argument
has to be convincing.
\begin{proof}
Take $f(x) = \ln\left(1 + e^x\right)$.
\end{proof}

\medskip


\noindent
{\bf Problem 8.}
Show that there is a unique continuous real valued
function $f:[0,1]\to\mathbb{R}$ such that
$$
f(x) = \sin x + \int_{0}^1 \frac{f(y)}{e^{x+y+1}}\, dy.
$$
\begin{proof}
Consider the map $T:C([0,1],\mathbb{R})\to C([0,1],\mathbb{R})$ defined by 
\begin{align*}
    T(f)(x) = \sin x + \int^1_0 \frac{f(y)}{e^{x+y+1}}\, dy = f(x).
\end{align*}
Clearly $f$ is a solution to the problem if and only if $T(f) = f$. Since $C([0,1],\mathbb{R})$ is compact, then we only need to show that $T$ is a contraction. Indeed, given $f,h\in C([0,1],\mathbb{R})$, we have
\begin{align*}
    d_\infty(T(f),T(h)) & = \sup_{x\in [0,1]} \left|\int_{0}^1 \frac{f(y)}{e^{x+y+1}}\, dy - \int_{0}^1 \frac{h(y)}{e^{x+y+1}}\, dy \right| \\
    & \leq \sup_{x\in [0,1]} \int^1_0 \frac{\left|f(y) - h(y)\right|}{e^{x+y+1}} \, dy \\
    & \leq d_\infty(f,h) \int^1_0 \frac{1}{e^{x+y+1}} \, dy \\
    & = d_\infty(f,h) (e-1)e^{-x-2}
\end{align*}
and we know that $(e-1)e^{-x-2} < 1$ for $x\in [0,1]$. Thus, $T$ is a contraction.
\end{proof}

\medskip


\noindent
{\bf Problem 9.}
Let $(X,d)$ be a nonempty complete metric space.
Let $S:X\to X$ be a given mapping and write $S^2$ for
$S\circ S$ i.e. $S^2(x)=S(S(x))$. Suppose that $S^2$ is a
contraction. Show that $S$ has a unique fixed point.
\begin{proof}
Since $S^2$ is conctraction, then there is a unique fixed point of $S^2$, denoted by $x^*$, such that $S^2(x^*) = x^*$. Then we have $S^2(S(x^*)) = S\left(S^2(x^*)\right) = S(x^*)$, which implies that $S(x^*)$ is also a fixed point of $S^2$. Thus, we have $S(x^*) = x^*$, implying $S$ has a unique fixed point.
\end{proof}
\begin{remark}
The argument in previous problem also holds if $S^n$ is a contraction.
\end{remark}

\medskip


\noindent
{\bf Problem 10.}
Let $E$ be a compact set and
let $\mathcal{F}\subset C(E,\mathbb{R})$ be an equicontinuous family
of functions. Does it imply that the family $\mathcal{F}$
is bounded in $C(E,\mathbb{R})$?
\begin{proof}
No. We can define $f_n(x) = n, \forall n\in \mathbb{N}, x\in E$. Thus, each $f_n(x), x\in E$ is equicontinuous function, hence $f_n(x) \in \mathcal{F}$. But, $\mathcal{F}$ is not bounded.
\end{proof}

\medskip


\noindent
{\bf Problem 11.}
Let $f:\mathbb{R}^n\to\mathbb{R}$ be bounded and uniformly continuous.
Prove that the family of functions $\{ g_z\}_{z\in\mathbb{R}^n}$,
$g_z(x)=f(x)f(x-z)$ is equicontinuous.
\begin{proof}
Since $f$ is bounded, then there exists a $M > 0$ such that for all $x\in\mathbb{R}^n$, $|f(x)| \leq M$. Since $f$ is uniformly continuous, then for all $\varepsilon > 0$, there exists $\delta > 0$ such that for all $x,y\in \mathbb{R}^n$, if $d(x,y) < \delta$, $|f(x) - f(y)| < \frac{\varepsilon}{2M}$. Then, for any $z\in \mathbb{R}^n$ we have $d(x-z, y-z) < \delta$, and $|f(x-z) - f(y-z)| < \frac{\varepsilon}{2M}$. Now we have
\begin{align*}
    |f(x)f(x-z) - f(y)f(y-z)| = & |f(x)f(x-z) - f(y)f(x-z) + f(y)f(x-z) \\
    & - f(y)f(y-z)| \\
    \leq & |f(x) - f(y)| \cdot |f(x-z)| + |f(x-z) - f(y-z)| \cdot |f(y)| \\
    \leq &  |f(x-z)| \frac{\varepsilon}{2M} + |f(y)| \frac{\varepsilon}{2M} \leq \varepsilon.
\end{align*}
Hence, for all $\varepsilon > 0$, there exists $\delta > 0$ such that for $\forall x,y$ and $\forall z$, if $d(x,y) < \delta$, then $d(g(x), g(y)) < \varepsilon$. Thus $\{ g_z\}_{z\in\mathbb{R}^n}$ is equicontinuous.
\end{proof}

\medskip

\noindent
{\bf Problem 12.}
Suppose $E$ is a compact metric space and $f_n:E\to\mathbb{R}$,
$n=1,2,\ldots$ is a bounded and equicontinuous sequence of functions. Suppose that $f_n$ converges pointwise to a continuous
function $f:E\to\mathbb{R}$ (i.e. $f_n(x)\to f(x)$ for every $x\in E$). Prove directly (i.e. without using Arzela-Ascoli theorem)
that $f_n\rightrightarrows f$ uniformly on $E$.
\begin{proof}
~\begin{enumerate}[label=(\arabic*)]
    \item Definition of pointwise convergence is that $f_n$ pointwise converges to $f$ if and only if $\lim_{n\to \infty}f_n(x) = f(x)$ for all $x\in E$, i.e., for any $x\in E$ and $\forall \varepsilon > 0$, there exists $N > 0$, such that for all $n \geq N$, $|f_n(x) - f(x)| < \varepsilon$. Here, the choice of $N$ depends on $x$ and $\varepsilon$.
    \item Definition of uniformly convergence is that for every $\varepsilon > 0$, there exists $N > 0$ such that for all $n\geq N$ and all $x\in E$, $|f_n(x) - f(x)| < \varepsilon$. Here the choice of $N$ works for all $x \in E$.
\end{enumerate}

As $\{f_n\}$ is equicontinuous, there exists a $\delta > 0$, such that for $\forall n \in\mathbb{N}$ and $\forall x,y\in E$:
\begin{align*}
    d(x,y) < \delta \Longrightarrow |f_n(x) - f_n(y)| < \frac{\varepsilon}{3}.
\end{align*}
and letting $n\to \infty$, then the above equation implies
\begin{align*}
    d(x,y) < \delta \Longrightarrow |f(x) - f(y)| < \frac{\varepsilon}{3}.
\end{align*}
Since $E$ is compact, then it can be covered by finite many open balls of radius $\delta$, i.e., there exists a $K > 0$ and $x_1, \cdots, x_K \in E$ such that 
\begin{align*}
    E \subset \bigcup^K_{j=1} B\left(x_j, \delta\right).
\end{align*}
As $f_n$ converges pointwise to $f$, then there exists $N > 0$ such that for $\forall n \geq N$, 
\begin{align*}
    |f_n(x_j) - f(x_j)| < \frac{\varepsilon}{3},
\end{align*}
for all $1\leq j \leq K$.

Now for any $x\in E$, and $\forall n \geq N$, then there exists a $j\in \{1,2,\cdots,K\}$, for which $x\in B(x_j,\delta)$, and hence
\begin{align*}
    |f_n(x) - f(x)| & \leq |f_n(x) - f_n(x_j)| + |f_n(x_j) - f(x_j)| + |f(x_j) - f(x)| \\
    & \leq \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
\end{align*}
Thus, $f_n\rightrightarrows f$ uniformly on $E$.
\end{proof}

\medskip

\noindent
{\bf Problem 13.}
Suppose $f_n:\mathbb{R}\to\mathbb{R}$,
$n=1,2,\ldots$ is a bounded and equicontinuous sequence of functions.
Suppose that $f_n$ converges pointwise to a continuous
function $f:\mathbb{R}\to\mathbb{R}$.
Does it imply that
$f_n\rightrightarrows f$ uniformly on $\mathbb{R}$?
\begin{proof}
No. We can take $f_n(x) = \frac{x}{n}$, which is converges pointwise to $f(x) = 0$, but it does not converges uniformly to $0$. Since for $\varepsilon = 1$, then we cannot find $N > 0$ such that for all $x\in\mathbb{R}$, $\frac{x}{N} < \varepsilon = 1$. 
\end{proof}

\medskip

\noindent
{\bf Problem 14.}
Let $f_n:[a,b]\to\mathbb{R}$ be a sequence
of increasing functions that is pointwise convergent to a
continuous function $f:[a,b]\to\mathbb{R}$. Prove that
$f_n\rightrightarrows f$ uniformly on $[a,b]$.
\begin{proof}
We want to show that for $\forall \varepsilon > 0$, there exists $N > 0$ such that for $\forall n \geq N$ and $\forall x\in [a,b]$, 
\begin{align*}
    |f_n(x) - f(x)| < \varepsilon.
\end{align*}

Let $g_n(x) = f(x) - f_n(x)$, then $g_n(x)$ is decreasing sequences of continuous functions. Let $\varepsilon > 0$, and 
\begin{align*}
    E_n = \{x\in [a,b]: g_n(x) = f(x) - f_n(x) < \varepsilon\}.
\end{align*}
Then $E_n$ is open since it is the inverse image of continuous function. And we can know that $\{E_n\}$ is an ascending sequence of open sets, since $g_n(x)$ is decreasing and if $x\in E_n$, then $g_n(x) < \varepsilon$ and of course $g_{n+1} < \varepsilon$, which implies $x\in E_{n+1}$. Then we have
\begin{align*}
    E_1\subset E_2\subset \cdots \subset E_n \subset \cdots 
\end{align*}
Now letting $n\to 0$, and we have $g_n(x)\to 0$. Then we will have the sets of $x\in [a,b]$ such that $g_n(x) < \varepsilon$ will be the set $[a,b]$. Then,
\begin{align*}
    [a,b] \subset \bigcup^\infty_{n=1} E_n,
\end{align*}
and since $[a,b]$ is compact, then there exists a finite subcover, such that 
\begin{align*}
    [a,b] \subset \bigcup^N_{n=1} E_n.
\end{align*}

Then for $\varepsilon > 0$ defined above, there exists $N > 0$ such that for all $\forall n \geq N$ and $\forall x\in [a,b]$, $|f_n(x) - f(x)| < \varepsilon$.
\end{proof}

\medskip

\noindent
{\bf Problem 15.}
Let  $\{f_n\}$ be a sequence of real valued $C^1$ functions on
$[0,1]$ such that, for all $n$,
$$
|f_n'(x)| \leq \frac{1}{\sqrt{x}}
\ \ (0<x\leq 1),
$$
$$
\int_0^1 f_n(x)\, dx = 0.
$$
Prove that the sequence has a subsequence that converges
uniformly on $[0,1]$.
\begin{proof}
~\begin{enumerate}[label=(\arabic*)]
    \item The second equation implies that there exists $x_n \in [0,1]$ such that $f_n(x_n) = 0$. Also, the first inequality implies
    \begin{align*}
        \left|f_n(x)\right| = \left|\int^{x}_{x_0} f_n'(t)\, dt\right| \leq \left|\int^{x}_{x_0} \frac{1}{\sqrt{t}}\, dt\right| = \left|2\sqrt{t} \Big|^{x}_{x_0} \right| = 2 \left|\sqrt{x} - \sqrt{x_0} \right| \leq 2,
    \end{align*}
    since $x\in [0,1]$. Thus, $f_n$ is bounded. 
    
    \item For $x,y\in [0,1]$ and $|x - y| < \delta = \frac{\varepsilon^2}{4}$, we have 
    \begin{align*}
        \left|f_n(x) - f_n(y)\right| = \left|\int^{x}_{y} f_n'(t)\, dt\right| \leq \left|\int^{x}_{y} \frac{1}{\sqrt{t}}\, dt\right| = 2 \left(\sqrt{y} - \sqrt{x}\right) \leq 2 \sqrt{y - x} < \varepsilon,
    \end{align*}
    where in the last step we used $\sqrt{y} - \sqrt{x} \leq \sqrt{y - x}$, since $\sqrt{y} = \sqrt{y-x+x} \leq \sqrt{y-x} + \sqrt{x}$. Thus, $\{f_n\}$ is equicontinuous.
\end{enumerate}
Hence, the family $\{f_n\}$ is bounded, closed and equicontinuous, then the sequence has a uniformly convergent subsequence.
\end{proof}

\medskip

\noindent
{\bf Problem 16.}
We know that every continuous function $f:[a,b]\to\mathbb{R}$ can be uniformly approximated by polynomials (Weierstrass' theorem). Prove that if
a continuous function $f:\mathbb{R}\to\mathbb{R}$ can be uniformly approximated by polynomials on all of $\mathbb{R}$, then $f$ is a polynomial. 
\begin{proof}
Suppose that $f$ can be uniformly approximated by polynomial $\{P_n(x)\}$ of degree at most $d$, and the polynomial $P_n(x)$ has the form
\begin{align*}
    P_n(x) = a^d_n x^d + \cdots + a^1_n x + a^0_n
\end{align*}
such that 
\begin{align*}
    \left|f(x) - P_n(x)\right| < \frac{1}{n}, \forall x\in \mathbb{R}.
\end{align*}
Then for any $m,n$, we have
\begin{align*}
    \left|P_n(x) - P_m(x)\right| \leq \left|P_n(x) - f(x)\right| + \left|f(x) - P_m(x)\right| < \frac{1}{n} + \frac{1}{m}
\end{align*}
which implies that $P_n(x) - P_m(x)$ is a polynomial which is bounded on $\mathbb{R}$ and hence a constant. Therefore, there exists some polynomial $P(x)$ and some $c_n \in \mathbb{R}$ such that 
\begin{align*}
    P_n(x) = P(x) + c_n.
\end{align*}
Also, we can have $|c_n - c_m| < \frac{1}{n} + \frac{1}{m}$, which implies $c_n$ is a Cauchy sequence, hence converging to a constant $c$.

Now we claim $f(x) = P(x) + c$. Let $\varepsilon > 0$, and pick $N = \frac{2}{\varepsilon}$, then for $\forall n > N$, we have $|c_n - c| < \frac{\varepsilon}{2}$. Now for $\forall n > N$, we have 
\begin{align*}
    |f(x) - P(x) - c| \leq |f(x) - P_n(x)| + |P_n(x) - P(x) - c| \leq \frac{1}{n} + |c_n - c| = \varepsilon.
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 17.}
Prove that if $f_n:\mathbb{R}\to\mathbb{R}$, $n=1,2,3,\ldots$ are differentiable functions such that
\begin{enumerate}
\item[(a)] $f_n(0)=0$ for all $n$,
\item[(b)] $|f_n'(x)|\leq e^x$ for all $n$ and all $x$, 
\end{enumerate}
then there is a subsequence of $f_n$ that converges pointwise to a continuous function $f:\mathbb{R}\to\mathbb{R}$.\\
{\bf Hint.} {\em Show that the family satisfies the assumptions of the Arzela-Ascoli theorem on every interval $[-n,n]$ and then apply the diagonal method.}
\begin{proof}
For any $x\in [-n,n]$, we have 
\begin{align*}
    \frac{|f_n(x) - f_n(0)|}{|x - 0|} = |f'(c)| \leq e^c < e^n,
\end{align*}
where $c\in (0,x)$ or $c\in (x,0)$. Then we have $|f_n(x)| < e^n n$ for all $n$ and $x\in [-n,n]$. Then $\{f_n\}$ is the set of bounded functions. Now we prove that $\{f_n\}$ is equicontinuous on interval $[-n,n]$. For any $\varepsilon > 0$, we pick $\delta = \frac{\varepsilon}{e^n}$. Then for any $x, y\in [-n,n]$, if $|x-y| < \delta$, then
\begin{align*}
    |f(x) - f(y)| = f'(c') |x-y| \leq e^n \frac{\varepsilon}{e^n} = \varepsilon,
\end{align*}
where $c' \in (x,y)$ or $c'\in (y,x)$. Thus, $\{f_n\}$ is equicontinuous. 

For interval $[-1,1]$, $\{f_n\}$ has a convergent subsequence, denoted by $f_{11},f_{12},\cdots$. Now the sequence $\{f_{1n}(x)\}$ is bounded on the interval $[-2,2]$, so it has convergent subsequence, denoted by $f_{21}, f_{22}, \cdots$. Contiune this process and we can have subsequences
\begin{align*}
    f_{11},f_{12},f_{13},\cdots \\
    f_{21},f_{22},f_{23},\cdots \\
    f_{31},f_{32},f_{33},\cdots
\end{align*}
Sequence in each line is a subsequence of the previous one. We now select $f_{11}, f_{22}, f_{33},\cdots$. 

We claim that $\{f_{nn}\}$ is uniformly convergent at every point of $\mathbb{R}$. Let $\varepsilon > 0$, and for any $x\in \mathbb{R}$, there exists $N > 0$, such that $x_i\in [-N,N]$ and $|x - x_i| < \delta$, where $\delta > 0$ as in the definition of equicontinuity. For $n,m \geq N$, we have
\begin{align*}
    \left|f_{nn}(x_i) - f_{mm}(x_i)\right| < \frac{\varepsilon}{3}, x\in [-N, N].
\end{align*}
Then we have
\begin{align*}
    |f_{nn}(x) - f_{mm}(x)| \leq |f_{nn}(x) - f_{nn}(x_i)| + |f_{nn}(x_i) - f_{mm}(x_i)| + |f_{mm}(x_i) - f_{mm}(x)| < \varepsilon.
\end{align*}
Hence $\{f_{nn}(x)\}$ is a Cauchy sequence. Now we define $$f(x) = \lim_{n\to\infty}f_{nn}(x),$$
and we can have
$$|f(x) - f_{nn}(x)| < \varepsilon$$
as $m\to\infty$.
\end{proof}

\medskip

\noindent
{\bf Problem 18.}
Let the functions $f_n:[0,1]\to [0,1]$, $n=1,2,\ldots$,
satisfy $|f_n(x)-f_n(y)|\leq |x-y|$ whenever $|x-y|\geq 1/n$.
Prove that the sequence $\{ f_n\}_{n=1}^\infty$ has a uniformly
convergent subsequence.
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\medskip

\noindent
{\bf Problem 19.}
If $f=(f_1,\ldots,f_n):[a,b]\to \mathbb{R}^n$ is a
continuous function, then we define
$$
\int_a^b f(t)\, dt =
\left\langle \int_a^b f_1(t)\, dt, \ldots, \int_a^b f_n(t)\, dt \right\rangle\, .
$$
Prove that
$$
\left\Vert \int_a^b f(t)\, dt \right\Vert \leq
\int_a^b \Vert f(t)\Vert\, dt.
$$
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\end{document}

\bigskip

\centerline{\bf\Large New problems}

\bigskip

\begin{problem}
Let the functions $f_n:[0,1]\to [0,1]$, $n=1,2,\ldots$,
satisfy $|f_n(x)-f_n(y)|\leq |x-y|$ whenever $|x-y|\geq 1/n$.
Prove that the sequence $\{ f_n\}_{n=1}^\infty$ has a uniformly
convergent subsequence.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
If $f=(f_1,\ldots,f_n):[a,b]\to \mathbb{R}^n$ is a
continuous function, then we define
$$
\int_a^b f(t)\, dt =
\left\langle \int_a^b f_1(t)\, dt, \ldots, \int_a^b f_n(t)\, dt \right\rangle\, .
$$
Prove that
$$
\left\Vert \int_a^b f(t)\, dt \right\Vert \leq
\int_a^b \Vert f(t)\Vert\, dt.
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}



\begin{problem}
Let $A=[a_{ij}]$ be the matrix of a linear mapping
$A\in L(\mathbb{R}^n,\mathbb{R}^m)$. Prove that the norm
$$
\Vert A\Vert=\sup_{\Vert x\Vert=1}\Vert Ax\Vert
$$
satisfies the inequality
$$
\Vert A\Vert \leq\left(\sum_{i=1}^m\sum_{j=1}^na_{ij}^2\right)^{1/2}
$$
{\em Hint:} You may use the following argument: Write the components of
the vector $Ax$ as scalar products of rows on $A$ and $x$.
Then use the Schwarz inequality to estimate the length of the vector $Ax$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove directly from the definition (do not use the Sylvester theorem)
that the matrix
$$
\left[
\begin{array}{ccc}
a    & b  \\
b    &  d
\end{array}
\right]
$$
is positive definite iff $a>0$ and $ad-b^2>0$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Write down an example of a function $f : \mathbb{R}^2 \to
\mathbb{R}$ such that the directional derivative $f_u (0,0)$ exists in
$\mathbb{R}$ for all unit vectors $u \in \mathbb{R}^2$, and yet $f$ is {\it
not} differentiable at $(0,0)$. Also, prove these two facts for
your example.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f:\mathbb{R}\to\mathbb{R}$ be differentiable and $F:\mathbb{R}^2\to\mathbb{R}$ be defined by
$F(x,y)=f(xy)$. Prove that
$$
x\frac{\partial F}{\partial x}=y\frac{\partial F}{\partial y}\, .
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
We say that a function $f:\mathbb{R}^n\to\mathbb{R}$ is homogeneous of degree $m$ if
$f(tx)=t^mf(x)$ for all $x\in\mathbb{R}^n$ and all $t>0$.
Prove that if $f$ is differentiable on $\mathbb{R}^n$ and homogeneous of
degree $m$, then
$$
\sum_{i=1}^n x_i\frac{\partial f}{\partial x_i}(x) = mf(x)
\quad
\mbox{for all $x\in\mathbb{R}^n$.}
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
We know that a function $f(x,y)$ is differentiable at $(0,0)$. We also know the
directional derivatives
$$
\begin{array}{ccc}
D_uf(0,0)=1    & \mbox{where $u=[1/\sqrt{5},2/\sqrt{5}]$,}\\
D_vf(0,0)=1 &   \mbox{where $v=[1/\sqrt{2},1/\sqrt{2}]$}.
\end{array}
$$
Find the gradient $\nabla f(0,0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f\in C^1(\mathbb{R}^2)$ be such that $f(1,1)=1$ and $\nabla f(1,1)=(a,b)$.
Let $\varphi(x)=f(x,f(x,f(x,x)))$. Find $\varphi(1)$ and $\varphi'(1)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
A function $f:\mathbb{R}^n\to\mathbb{R}$ is differentiable. Find the derivative of the function
$$
F(t)=(f(t,t^2,\ldots,t^n))^2,\quad t\in\mathbb{R}
$$
of one variable.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Verify by a direct computation that the vector field $F(x)=x|x|^{-n}$ defined on
$\mathbb{R}^n\setminus\{0\}$ is divergence free, i.e.
$$
{\rm div}\, F(x)=\sum_{i=1}^n \frac{\partial}{\partial x_i}\left(\frac{x_i}{|x|^n}\right) = 0
\quad
\mbox{for all $x\neq 0$.}
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that for $\alpha>0$ the function $\Phi:\mathbb{R}^n\to\mathbb{R}^n$,
$$
\Phi(x)=x|x|^\alpha
$$
is of class $C^1$. Find $D\Phi(x)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Find all the points $(x,y)\in\mathbb{R}^2$ where the function
$$
f(x,y)=|e^x-e^y|\cdot(x+y-2)
$$
is differentiable.

\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Consider the function $g : \mathbb{R}^2 \to \mathbb{R}$ given by
$$
g(x, y) = x^{2/3}y^{2/3}, \ \text{for all} \ (x, y) \in \mathbb{R}^2 \,
.
$$
Prove that $g$ is {\it differentiable} at $(0, 0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Find a function $f:\mathbb{R}^2\to\mathbb{R}$ that is differentiable at each point,
but whose partial derivatives are not continuous at $(0,0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that is the partial derivatives (of first order) of a function
$f:\mathbb{R}^n\to\mathbb{R}$ exist everywhere and they are bounded, then
the function $f$ is continuous.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that if $f,g\in C^k(\Omega)$, $\Omega\subset\mathbb{R}^n$, then for any multiindex
$\alpha$ with $|\alpha|\leq k$ we have
$$
D^\alpha(fg)=\sum_{\beta\leq \alpha}\binom{\alpha}{\beta}D^\beta f D^{\alpha-\beta}g\, ,
$$
where
$\beta\leq\alpha$ means that $\beta_i\leq\alpha_i$ for $i=1,2,\ldots,n$,
$\alpha-\beta=(\alpha_1-\beta_1,\ldots,\alpha_n-\beta_n)$ and 
$$
\binom{\alpha}{\beta}=\frac{\alpha!}{\beta!(\alpha-\beta)!}\, .
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f\in C^2(\mathbb{R}^2)$. Suppose that $\nabla f=0$ on a compact set
$E\subset\mathbb{R}^2$. Prove that there is a constant $M>0$ such that
$|f(x)-f(y)|\leq M|x-y|^2$ for all $x,y\in E$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}[A smooth function with compact support] 
Consider an open ball $B=B(a,r)\subset\mathbb{R}^n$. Prove that the function
$$
\varphi(x)
          = \left\{\begin{array}{ccc}
            \exp\left(\frac{1}{|x-a|^2-r^2}\right)       &  \mbox{if $x\in B$}\, , \\
             0     &  \mbox{if $x\in \mathbb{R}^n\setminus B$}\, ,
               \end{array}
        \right.
$$
in infinitely differentiable on $\mathbb{R}^n$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}




\begin{problem}
Let $A=[a_{ij}]$ be an $n\times n$ matrix. The {\em cofactor} $A_{i,j}$
is the product of $(-1)^{i+j}$ with the $(n-1)\times(n-1)$ determinant of $A$ obtained by deleting the
$i$th row and $j$th column in $A$.  Prove that
$$
\frac{\partial}{\partial a_{ij}}(\det A)=A_{ij}.
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Let $A(t)=[x_{ij}(t)]:(a,b)\to\mathbb{R}^{n\times n}$ be a smooth matrix-valued curve.
Prove that if $A(0)=I$, then
$$
\frac{d}{dt}|_{t=0}(\det A(t))=\sum_{i=1}^n x_{ii}'(0)={\rm tr}\, A'(0).
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Let $\Omega=\{(x,y)\in\mathbb{R}^2:\, x>0, 0<y<2\pi\}$.
Prove that the mapping $f:\Omega\to\mathbb{R}^2$,
$f(x,y)=(x\cos y,x\sin y)$ is a diffeomorphism of $\Omega$
onto an open subset of $\mathbb{R}^2$. Find $f(\Omega)$.
{\em Hint:} A picture will help. Have you seen a similar mapping in Calculus~3?
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Find a diffeomorphism of $\mathbb{R}^2$ onto the open unit disc $x^2+y^2<1$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Find a diffeomorphism of the upper half plane $y>0$ onto the first quadrant
$x>0$, $y>0$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Suppose that $f\in C^1(\mathbb{R})$ is such that $|f'(x)|<1$ for all $x\in\mathbb{R}$.
Prove that the mapping $F:\mathbb{R}^2\to\mathbb{R}^2$,
$F(x,y)=(x+f(y), y-f(x))$
is a diffeomorphism in a neighborhood of any point $(x,y)\in\mathbb{R}^2$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that a complex polynomial
$P(z)=a_0z^n+a_1 z^{n-1} + \ldots + a_n$
regarded as a function
$P:\mathbb{R}^2\to\mathbb{R}^2$ is a diffeomorphism in a neighborhood of $z_0\in\mathbb{C}$
if and only if $P'(z_0)\neq 0$, where
$P'(z)=na_0 z^{n-1} + (n-1)a_1 z^{n-2} + \ldots + a_1$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f:\mathbb{R}\to\mathbb{R}$ be $C^1$ and let
\begin{eqnarray*}
u & = & f(x) \\
v & = & -y+xf(x).
\end{eqnarray*}
If $f'(x_0)\neq 0$, show that this transformation is locally
invertible near $(x_0,y_0)$ and the inverse has the form
\begin{eqnarray*}
x & = & g(u) \\
y & = & -v+ug(u).
\end{eqnarray*}
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
A $C^2$ function $f:\mathbb{R}^2\to\mathbb{R}$ is called harmonic if
$$
\frac{\partial^2 f}{\partial x^2} +
\frac{\partial^2 f}{\partial y^2} = 0\, .
$$
Prove that if a harmonic function has a local maximaum at $(x_0,y_0)$, then
{\em all} second order partial derivatives of $f$ vanish at $(x_0,y_0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Suppose that a function $f:\mathbb{R}^2\to\mathbb{R}$ of class $C^2$
satisfies the inequality $f_{xx}+f_{yy}\geq 0$ at every point 
of $\mathbb{R}^2$. Suppose also that all its critical points are non-degenerate, i.e. the matrix of second order derivatives 
at the critical point has non-zero determinant.
Prove that $f$ cannot have local maxima.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that the system of equations
$$
\left\{
\begin{array}{ccc}
xyz+x^2+y=0\\
z+x^2y^2z^2=0\end{array}
\right.
$$
has a solution of the form $y=y(x), z=z(x)$ in a neighborhood of
$(0,0,0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
\label{P1}
Let $F(x,y)=x^3y^2+3x^2y^3-xy+2x-y^2+1$, $(x,y)\in\mathbb{R}^2$. Prove that
there exist functions $g,h\in C^\infty$ defined on an open neighborhood
$U\subset\mathbb{R}$ of $0$, such that $F(x,g(x))=0=F(x,h(x))$ and
$g(x)<h(x)$ for every $x\in U$. Find $g'(0)$, $h'(0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Suppose that $F:\mathbb{R}^3\to\mathbb{R}$ is of class $C^1$.
$F(0,0,0)=0$, $F_x(0,0,0)\neq 0$, $F_y(0,0,0)\neq 0$,
$F_z(0,0,0)\neq 0$. The implicit function theorem implies
that the equation $F(x,y,z)=0$ can uniquely be solved in a
neighborhood of the point $(0,0,0)$
as $x=x(y,z)$ or $y=y(x,z)$ or $z=z(x,y)$. Prove that
at every point in some neighborhood of $(0,0,0)$ we have
$$
\frac{\partial z}{\partial x} \frac{\partial x}{\partial y}
\frac{\partial y}{\partial z}=-1\, .
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Let $F$ be as in Problem~\ref{P1}. Prove that there is a function $g\in C^\infty$
defined on an open neighborhood $U$ of $0$ such that $F(g(y),y)=0$
for every $y\in U$. Find $g'(0)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Let $F=F(x,y):\mathbb{R}^2\to\mathbb{R}$ be of class $C^1$ such that
$\partial F/\partial y\neq 0$ on $\mathbb{R}^2$.
Prove that if the set
$S=\{ (x,y)\, |\, F(x,y)=0\}$ is nonempty, then it is of the form
$S=\{ (x,g(x))\, |\, x\in U\}$, where $g:U\to\mathbb{R}$ is a $C^1$ function
defined on an open set $U\subset\mathbb{R}$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that the equation $xe^z=y(z+x)$ defines $z$ as a function of $(x,y)$ in a neighborhood of the point 
$(x_0,y_0,z_0)=(2,1,0)$. Then find the Taylr polynomial 
of degree $2$ of the function $z=z(x,y)$ centered at the point
$(2,1)$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Show that there is a polynomial $P(x,y,z)$ of order $4$ such that
the set $P(x,y,z)=0$ is a torus. Show that the gradient of $P$ is
nonzero at every point of the torus and conclude that the torus is
locally a graph of a smooth function of two variables.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Show that there is no polynomial $P(x,y,z)$ of order less than $4$ such
that the set $P(x,y,z)=0$ is a torus.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}




\begin{problem}
The cylinder $(x-1)^2+y^2=1$ intersects with the sphere $x^2+y^2+z^2=4$
along a curve. This curve has a self-intersection
(the curve looks like "8"). Find the angle at which the curve
intersects with itself.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
Let $M_{n\times n}$ denote the vector space of real $n\times n$ matrices.
Define a map $f:M_{n\times n}\to M_{n\times n}$ by $f(X)=X^2$.
Find the derivative of $f$.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
The class of invertible matrices
$GL(n,\mathbb{R})$ forms an open subset in the space of all $n\times n$ matrices $M_{n\times n}=\mathbb{R}^{n^2}$.
Let $F:GL(n,\mathbb{R})\to GL(n,\mathbb{R})$, $F(A)=A^{-1}$. 
Prove that the function $F$ is $C^\infty$ smooth (as a mapping from $\mathbb{R}^{n^2}$ to $\mathbb{R}^{n^2}$) and that
for any $A\in\mathbb{R}^{n\times n}$ we have
$$
DF(A)B=-A^{-1}\circ B\circ A^{-1}
\quad
\text{for all $B\in \mathbb{R}^{n\times n}$}
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\centerline{\bf Even more problems}

\begin{problem}
Let $f:\mathbb{R}\to\mathbb{R}$ be continuous. Suppose that $\mathbb{R}$ contains
a countably infinite subset $S$ such that
$$
\int_p^q f(x)\, dx =0
$$
if $p$ and $q$ are not in $S$. Prove that $f$ is identically zero.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f$ be a real valued $C^1$ function on $[0,\infty)$ such that
the improper integral $\int_1^\infty |f'(x)|\, dx$ converges. Prove that
the infinite series $\sum_{n=1}^\infty f(n)$ converges if and only if
$\int_1^\infty f(x)\, dx$ converges.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem} $\phantom{a}$
\noindent
{\bf (a)} Prove that
$$
\int_0^\infty \left( \sum_{n=1}^\infty (-1)^{n+1} e^{-nx}\right)\, dx =
\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}.
$$
(If you formally interchange the sum with the integral, then you are done.
But can you really do it? It needs to be properly justified!)

\noindent
{\bf (b)} Use part (a) to show that
$$
\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n} = \ln 2.
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f$ be a continuous function on $[0,1]$. Evaluate the following limits
\begin{enumerate}
\item
$\displaystyle \lim_{n\to\infty} \int_0^1 x^n f(x)\, dx$
\item
$\displaystyle \lim_{n\to\infty} n\int_{0}^1 x^nf(x)\, dx$.
\end{enumerate}
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that the standard Cantor set $C\subset [0,1]$ has measure zero.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Prove that $\mathbb{R}^{n-1}\subset\mathbb{R}^n$ has measure zero.
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
If $f$ is continuous, show that
$$
\int_0^x\int_0^y\int_0^z f(t)\, dt\, dz\, dy =
\frac{1}{2}\int_0^x (x-t)^2f(t)\, dt.
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Let $f,g:[a,b]\to\mathbb{R}$ be continuous with $g$ being
nonnegative. Prove that there is $\xi\in [a,b]$ such
that
$$
\int_a^b f(x)g(x)\, dx = f(\xi)\int_a^b g(x)\, dx.
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
Find the limit
$$
\lim_{n\to\infty}
\frac{1^m + 2^m+\ldots+n^m}{n^{m+1}}.
$$
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2005, Problem 2
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2005, Problem 3
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2005 Problem 4
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2005 Problem 6
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2005 Problem 5
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2005 Problem 9
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2007 Problem 5
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2007 Problem 6 
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2009 Problem 2
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}


\begin{problem}
PE April 2009 Problem 5
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2009 Problem 6 (You must use Lagrange Multiplier)
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2009 Problem 2
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2009 Problem 5
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2009 Problem 6
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2010 Problem 3
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 2010 Problem 6
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2011 Problem 2
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 2011 Problem 5
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE April 12 Problem 6
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 12 Problem 3
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\begin{problem}
PE August 12 Problem 6
\end{problem}
\begin{proof}
WRITE YOUR SOLUTION HERE.
\end{proof}

\end{document}


